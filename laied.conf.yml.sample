# Aider Configuration File
# 
# This file configures aider's behavior. Copy this to .aider.yml in your
# project directory, git repository root, or home directory.
#
# Documentation: https://aider.chat/docs/config/

# Provider configurations - define your AI service endpoints
providers:
  # OpenAI configuration
  openai_main:
    type: openai
    api_key: "sk-your-openai-api-key-here"
    base_url: "https://api.openai.com/v1"
    models:
      - "gpt-4"
      - "gpt-4-turbo" 
      - "gpt-4o"
      - "gpt-4o-mini"
      - "gpt-3.5-turbo"

  # Anthropic configuration
  anthropic_main:
    type: anthropic
    api_key: "sk-ant-your-anthropic-key-here"
    models:
      - "claude-3-5-sonnet-20241022"
      - "claude-3-5-haiku-20241022"
      - "claude-sonnet-4-20250514"

  # Local Ollama configuration
  local_ollama:
    type: ollama
    base_url: "http://localhost:11434"
    models:
      - "llama3:8b"
      - "llama3:70b"
      - "codellama:7b"
      - "codellama:13b"
      - "mistral:7b"

  # Example: Multiple OpenAI endpoints
  # openai_azure:
  #   type: openai
  #   api_key: "your-azure-key"
  #   base_url: "https://your-company.openai.azure.com"
  #   models:
  #     - "gpt-4-azure"

  # Example: Remote Ollama server
  # remote_ollama:
  #   type: ollama
  #   base_url: "http://gpu-server:11434"
  #   api_key: "optional-auth-token"
  #   models:
  #     - "llama3:70b"

# Model aliases for easy switching
model_aliases:
  # Common model aliases
  sonnet: "anthropic_main/claude-3-5-sonnet-20241022"
  haiku: "anthropic_main/claude-3-5-haiku-20241022"
  gpt4: "openai_main/gpt-4"
  gpt4o: "openai_main/gpt-4o"
  gpt4o-mini: "openai_main/gpt-4o-mini"
  gpt35: "openai_main/gpt-3.5-turbo"
  
  # Local model aliases
  llama: "local_ollama/llama3:8b"
  llama-big: "local_ollama/llama3:70b"
  codellama: "local_ollama/codellama:7b"

# Default model configuration
model: "sonnet"                              # Main model for coding tasks
weak_model: "openai_main/gpt-3.5-turbo"     # Model for simple tasks like commit messages
editor_model: "local_ollama/codellama:7b"   # Model for editor tasks (optional)

# Model-specific settings
model_settings:
  # OpenAI models
  "openai_main/gpt-4":
    max_tokens: 4096
    temperature: 0.1
  
  "openai_main/gpt-4o":
    max_tokens: 4096
    temperature: 0.1
  
  # All local Ollama models
  "local_ollama/*":
    temperature: 0.0
    stream: true

  # Specific model settings
  "anthropic_main/claude-3-5-sonnet-20241022":
    max_tokens: 8192
    temperature: 0.1

# Git settings
git:
  auto_commits: true                     # Automatically commit changes
  commit_prefix: "aider: "              # Prefix for commit messages
  auto_add: true                        # Automatically add files to git
  dirty_commits: true                   # Allow commits when repo is dirty
  attribute_author: true                # Attribute changes to aider in git
  attribute_committer: true             # Set aider as committer
  dry_run: false                        # Don't actually make changes (for testing)

# Output and display settings
output:
  user_input_color: "#00cc00"           # Color for user input
  tool_output_color: null               # Color for tool output (null = default)
  tool_error_color: "#FF2222"           # Color for error messages
  tool_warning_color: "#FFA500"         # Color for warning messages
  assistant_output_color: "#0088ff"     # Color for AI responses
  code_theme: "default"                 # Code syntax highlighting theme
  stream: true                          # Stream responses as they come
  pretty: true                          # Enable colorized output
  show_diffs: false                     # Show diffs when committing
  show_repo_map: false                  # Show repository map
  show_model_warnings: true             # Show model capability warnings
  verbose: false                        # Enable verbose output

# Caching configuration
cache:
  cache_prompts: false                  # Cache prompts to reduce costs
  cache_keepalive_pings: 0              # Keep cache warm with pings

# Repository mapping settings
repomap:
  map_tokens: 1024                      # Tokens to use for repo map
  map_refresh: "auto"                   # When to refresh map (auto/always/files/manual)
  map_multiplier_no_files: 2.0          # Map token multiplier when no files specified
  repo_map: true                        # Enable repository mapping

# Voice settings (if using voice input)
voice:
  voice_format: "wav"                   # Audio format (wav/mp3/webm)
  voice_language: "en"                  # Language for voice recognition

# Analytics settings
analytics:
  analytics: true                       # Enable usage analytics
  analytics_log: null                   # File to log analytics (optional)

# Other settings
edit_format: "diff"                     # Default edit format (diff/whole/udiff/architect)
encoding: "utf-8"                       # File encoding
vim: false                              # Use vim-style editing
check_update: true                      # Check for updates on startup

# Advanced settings (uncomment and modify as needed)
# 
# max_chat_history_tokens: 1024         # Max tokens for chat history
# line_endings: "platform"              # Line ending style (platform/lf/crlf)
# notifications: false                   # Enable desktop notifications
# fancy_input: true                      # Enable rich input with history
# multiline: false                       # Enable multi-line input mode
# suggest_shell_commands: true           # Suggest shell commands